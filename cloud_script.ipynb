{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2ec5b470",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ec5b470",
        "outputId": "27f3419f-31d3-43ea-92d4-ad45e189828a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MIEEG' already exists and is not an empty directory.\n",
            "Mounted at drive/\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Lolleeee/MIEEG\n",
        "import os\n",
        "os.environ['DATASET_FOLDER'] = 'dataset'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/Colab_env/WAY-EEG/WAYEEG_DATASET_DL.zip -d dataset"
      ],
      "metadata": {
        "id": "aveRxZF0Jhgz"
      },
      "id": "aveRxZF0Jhgz",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPo22FjlMiRh"
      },
      "id": "sPo22FjlMiRh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5473cd8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "5473cd8f",
        "outputId": "881fdd0b-4c3f-4b11-be91-5a92ac6651b7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'packages'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-696723178.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoencoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv3DAutoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_data_loaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'packages'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from packages.models.Autoencoder import Conv3DAutoencoder\n",
        "from packages.train.training import train_model\n",
        "from packages.io.input_loader import get_data_loaders\n",
        "import torch\n",
        "import os\n",
        "from packages.data_objects.dataset import Dataset\n",
        "from dotenv import load_dotenv\n",
        "model = Conv3DAutoencoder(in_channels=50, embedding_dim=256)\n",
        "load_dotenv()\n",
        "dataset_path = \"dataset/WAYEEG_processed/patient1\"\n",
        "# Dummy training loop\n",
        "optimizer = torch.optim.AdamW\n",
        "criterion = torch.nn.MSELoss\n",
        "mae = torch.nn.L1Loss\n",
        "\n",
        "config = {\n",
        "    'batch_size': 32,\n",
        "    'lr': 1e-3,\n",
        "    'epochs': 5,\n",
        "    'backup_interval': 10,\n",
        "    'EarlyStopping' : {'patience': 1, 'min_delta': 0.1},\n",
        "    'BackupManager': {'backup_interval': 10, 'backup_path': './model_backups'},\n",
        "    'ReduceLROnPlateau': {'mode': 'min', 'patience': 1, 'factor': 0.1},\n",
        "    'history_plot': {'plot_type': 'extended', 'save_path': './training_history'}\n",
        "}\n",
        "\n",
        "metrics = {'MAE': mae}\n",
        "\n",
        "dataset = Dataset(root_folder=dataset_path, unpack_func='dict', nsamples=4)\n",
        "\n",
        "train_loader, val_loader, _ = get_data_loaders(dataset, sets_size={'train': 0.7, 'val': 0.3, 'test': 0})\n",
        "\n",
        "print(\"\\nStarting training loop...\")\n",
        "model.train()\n",
        "train_model(model, train_loader=train_loader, val_loader=val_loader, loss_criterion=criterion, optimizer=optimizer, config=config, metrics=metrics)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}